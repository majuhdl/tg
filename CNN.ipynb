{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AK0gtapirAF",
        "outputId": "2aefe2e8-b0c0-43fe-ed23-3eddc69fec52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([['5.1', '3.5', '1.4', '0.2'],\n",
            "       ['4.9', '3.0', '1.4', '0.2'],\n",
            "       ['4.7', '3.2', '1.3', '0.2'],\n",
            "       ['4.6', '3.1', '1.5', '0.2'],\n",
            "       ['5.0', '3.6', '1.4', '0.2'],\n",
            "       ['5.4', '3.9', '1.7', '0.4'],\n",
            "       ['4.6', '3.4', '1.4', '0.3'],\n",
            "       ['5.0', '3.4', '1.5', '0.2'],\n",
            "       ['4.4', '2.9', '1.4', '0.2'],\n",
            "       ['4.9', '3.1', '1.5', '0.1'],\n",
            "       ['5.4', '3.7', '1.5', '0.2'],\n",
            "       ['4.8', '3.4', '1.6', '0.2'],\n",
            "       ['4.8', '3.0', '1.4', '0.1'],\n",
            "       ['4.3', '3.0', '1.1', '0.1'],\n",
            "       ['5.8', '4.0', '1.2', '0.2'],\n",
            "       ['5.7', '4.4', '1.5', '0.4'],\n",
            "       ['5.4', '3.9', '1.3', '0.4'],\n",
            "       ['5.1', '3.5', '1.4', '0.3'],\n",
            "       ['5.7', '3.8', '1.7', '0.3'],\n",
            "       ['5.1', '3.8', '1.5', '0.3'],\n",
            "       ['5.4', '3.4', '1.7', '0.2'],\n",
            "       ['5.1', '3.7', '1.5', '0.4'],\n",
            "       ['4.6', '3.6', '1.0', '0.2'],\n",
            "       ['5.1', '3.3', '1.7', '0.5'],\n",
            "       ['4.8', '3.4', '1.9', '0.2'],\n",
            "       ['5.0', '3.0', '1.6', '0.2'],\n",
            "       ['5.0', '3.4', '1.6', '0.4'],\n",
            "       ['5.2', '3.5', '1.5', '0.2'],\n",
            "       ['5.2', '3.4', '1.4', '0.2'],\n",
            "       ['4.7', '3.2', '1.6', '0.2'],\n",
            "       ['4.8', '3.1', '1.6', '0.2'],\n",
            "       ['5.4', '3.4', '1.5', '0.4'],\n",
            "       ['5.2', '4.1', '1.5', '0.1'],\n",
            "       ['5.5', '4.2', '1.4', '0.2'],\n",
            "       ['4.9', '3.1', '1.5', '0.2'],\n",
            "       ['5.0', '3.2', '1.2', '0.2'],\n",
            "       ['5.5', '3.5', '1.3', '0.2'],\n",
            "       ['4.9', '3.6', '1.4', '0.1'],\n",
            "       ['4.4', '3.0', '1.3', '0.2'],\n",
            "       ['5.1', '3.4', '1.5', '0.2'],\n",
            "       ['5.0', '3.5', '1.3', '0.3'],\n",
            "       ['4.5', '2.3', '1.3', '0.3'],\n",
            "       ['4.4', '3.2', '1.3', '0.2'],\n",
            "       ['5.0', '3.5', '1.6', '0.6'],\n",
            "       ['5.1', '3.8', '1.9', '0.4'],\n",
            "       ['4.8', '3.0', '1.4', '0.3'],\n",
            "       ['5.1', '3.8', '1.6', '0.2'],\n",
            "       ['4.6', '3.2', '1.4', '0.2'],\n",
            "       ['5.3', '3.7', '1.5', '0.2'],\n",
            "       ['5.0', '3.3', '1.4', '0.2'],\n",
            "       ['7.0', '3.2', '4.7', '1.4'],\n",
            "       ['6.4', '3.2', '4.5', '1.5'],\n",
            "       ['6.9', '3.1', '4.9', '1.5'],\n",
            "       ['5.5', '2.3', '4.0', '1.3'],\n",
            "       ['6.5', '2.8', '4.6', '1.5'],\n",
            "       ['5.7', '2.8', '4.5', '1.3'],\n",
            "       ['6.3', '3.3', '4.7', '1.6'],\n",
            "       ['4.9', '2.4', '3.3', '1.0'],\n",
            "       ['6.6', '2.9', '4.6', '1.3'],\n",
            "       ['5.2', '2.7', '3.9', '1.4'],\n",
            "       ['5.0', '2.0', '3.5', '1.0'],\n",
            "       ['5.9', '3.0', '4.2', '1.5'],\n",
            "       ['6.0', '2.2', '4.0', '1.0'],\n",
            "       ['6.1', '2.9', '4.7', '1.4'],\n",
            "       ['5.6', '2.9', '3.6', '1.3'],\n",
            "       ['6.7', '3.1', '4.4', '1.4'],\n",
            "       ['5.6', '3.0', '4.5', '1.5'],\n",
            "       ['5.8', '2.7', '4.1', '1.0'],\n",
            "       ['6.2', '2.2', '4.5', '1.5'],\n",
            "       ['5.6', '2.5', '3.9', '1.1'],\n",
            "       ['5.9', '3.2', '4.8', '1.8'],\n",
            "       ['6.1', '2.8', '4.0', '1.3'],\n",
            "       ['6.3', '2.5', '4.9', '1.5'],\n",
            "       ['6.1', '2.8', '4.7', '1.2'],\n",
            "       ['6.4', '2.9', '4.3', '1.3'],\n",
            "       ['6.6', '3.0', '4.4', '1.4'],\n",
            "       ['6.8', '2.8', '4.8', '1.4'],\n",
            "       ['6.7', '3.0', '5.0', '1.7'],\n",
            "       ['6.0', '2.9', '4.5', '1.5'],\n",
            "       ['5.7', '2.6', '3.5', '1.0'],\n",
            "       ['5.5', '2.4', '3.8', '1.1'],\n",
            "       ['5.5', '2.4', '3.7', '1.0'],\n",
            "       ['5.8', '2.7', '3.9', '1.2'],\n",
            "       ['6.0', '2.7', '5.1', '1.6'],\n",
            "       ['5.4', '3.0', '4.5', '1.5'],\n",
            "       ['6.0', '3.4', '4.5', '1.6'],\n",
            "       ['6.7', '3.1', '4.7', '1.5'],\n",
            "       ['6.3', '2.3', '4.4', '1.3'],\n",
            "       ['5.6', '3.0', '4.1', '1.3'],\n",
            "       ['5.5', '2.5', '4.0', '1.3'],\n",
            "       ['5.5', '2.6', '4.4', '1.2'],\n",
            "       ['6.1', '3.0', '4.6', '1.4'],\n",
            "       ['5.8', '2.6', '4.0', '1.2'],\n",
            "       ['5.0', '2.3', '3.3', '1.0'],\n",
            "       ['5.6', '2.7', '4.2', '1.3'],\n",
            "       ['5.7', '3.0', '4.2', '1.2'],\n",
            "       ['5.7', '2.9', '4.2', '1.3'],\n",
            "       ['6.2', '2.9', '4.3', '1.3'],\n",
            "       ['5.1', '2.5', '3.0', '1.1'],\n",
            "       ['5.7', '2.8', '4.1', '1.3'],\n",
            "       ['6.3', '3.3', '6.0', '2.5'],\n",
            "       ['5.8', '2.7', '5.1', '1.9'],\n",
            "       ['7.1', '3.0', '5.9', '2.1'],\n",
            "       ['6.3', '2.9', '5.6', '1.8'],\n",
            "       ['6.5', '3.0', '5.8', '2.2'],\n",
            "       ['7.6', '3.0', '6.6', '2.1'],\n",
            "       ['4.9', '2.5', '4.5', '1.7'],\n",
            "       ['7.3', '2.9', '6.3', '1.8'],\n",
            "       ['6.7', '2.5', '5.8', '1.8'],\n",
            "       ['7.2', '3.6', '6.1', '2.5'],\n",
            "       ['6.5', '3.2', '5.1', '2.0'],\n",
            "       ['6.4', '2.7', '5.3', '1.9'],\n",
            "       ['6.8', '3.0', '5.5', '2.1'],\n",
            "       ['5.7', '2.5', '5.0', '2.0'],\n",
            "       ['5.8', '2.8', '5.1', '2.4'],\n",
            "       ['6.4', '3.2', '5.3', '2.3'],\n",
            "       ['6.5', '3.0', '5.5', '1.8'],\n",
            "       ['7.7', '3.8', '6.7', '2.2'],\n",
            "       ['7.7', '2.6', '6.9', '2.3'],\n",
            "       ['6.0', '2.2', '5.0', '1.5'],\n",
            "       ['6.9', '3.2', '5.7', '2.3'],\n",
            "       ['5.6', '2.8', '4.9', '2.0'],\n",
            "       ['7.7', '2.8', '6.7', '2.0'],\n",
            "       ['6.3', '2.7', '4.9', '1.8'],\n",
            "       ['6.7', '3.3', '5.7', '2.1'],\n",
            "       ['7.2', '3.2', '6.0', '1.8'],\n",
            "       ['6.2', '2.8', '4.8', '1.8'],\n",
            "       ['6.1', '3.0', '4.9', '1.8'],\n",
            "       ['6.4', '2.8', '5.6', '2.1'],\n",
            "       ['7.2', '3.0', '5.8', '1.6'],\n",
            "       ['7.4', '2.8', '6.1', '1.9'],\n",
            "       ['7.9', '3.8', '6.4', '2.0'],\n",
            "       ['6.4', '2.8', '5.6', '2.2'],\n",
            "       ['6.3', '2.8', '5.1', '1.5'],\n",
            "       ['6.1', '2.6', '5.6', '1.4'],\n",
            "       ['7.7', '3.0', '6.1', '2.3'],\n",
            "       ['6.3', '3.4', '5.6', '2.4'],\n",
            "       ['6.4', '3.1', '5.5', '1.8'],\n",
            "       ['6.0', '3.0', '4.8', '1.8'],\n",
            "       ['6.9', '3.1', '5.4', '2.1'],\n",
            "       ['6.7', '3.1', '5.6', '2.4'],\n",
            "       ['6.9', '3.1', '5.1', '2.3'],\n",
            "       ['5.8', '2.7', '5.1', '1.9'],\n",
            "       ['6.8', '3.2', '5.9', '2.3'],\n",
            "       ['6.7', '3.3', '5.7', '2.5'],\n",
            "       ['6.7', '3.0', '5.2', '2.3'],\n",
            "       ['6.3', '2.5', '5.0', '1.9'],\n",
            "       ['6.5', '3.0', '5.2', '2.0'],\n",
            "       ['6.2', '3.4', '5.4', '2.3'],\n",
            "       ['5.9', '3.0', '5.1', '1.8'],\n",
            "       ['1000000000', '100000000000', '1000000000', 'blob'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000'],\n",
            "       ['1000000000', '100000000000', '1000000000', '1000000000']],\n",
            "      dtype='<U32'), 'target': array([             0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "#Load dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = np.array([[1000000000, 100000000000, 1000000000, \"blob\"], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000], [1000000000, 100000000000, 1000000000, 1000000000]])\n",
        "Y = [10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000, 10000000000000]\n",
        "\n",
        "iris['data'] = np.vstack([iris['data'], X])\n",
        "iris['target'] = np.hstack([iris['target'], Y])\n",
        "\n",
        "print(iris)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import typing as t\n",
        "\n",
        "class Filter:\n",
        "    \"\"\"Base class for all the implemented class noise filters.\n",
        "    Attributes\n",
        "    ----------\n",
        "    rem_indx : :obj:`List`\n",
        "        Removed indexes (rows) from the dataset after the filtering.\n",
        "    parameters : :obj:`Dict`\n",
        "        Parameters used to define the behaviour of the filter.\n",
        "    clean_data : :obj:`Sequence`\n",
        "        Filtered independent attributes(X) of the dataset.\n",
        "    clean_classes : :obj:`Sequence`\n",
        "        Filtered target attributes(y) of the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parameters: t.Dict):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        parameters : :obj:`Dict`\n",
        "            Dictionary that provides hyperparameters for filters algorithms.\n",
        "        \"\"\"\n",
        "        # Removed Indexes\n",
        "        self.rem_indx: t.List = []\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def set_cleanData(self, attributes: t.Sequence, labels: t.Sequence) -> t.NoReturn:\n",
        "        \"\"\"Helper function to set data and classes to Filter instance.\n",
        "        Parameters\n",
        "        ----------\n",
        "        data : :obj:`Sequence`\n",
        "            Filtered independent attributes(X) of the dataset.\n",
        "        classes : :obj:`Sequence`\n",
        "            Filtered target attributes(y) of the dataset.\n",
        "        \"\"\"\n",
        "        self.clean_data = attributes\n",
        "        self.clean_classes = labels"
      ],
      "metadata": {
        "id": "5TEAZ4Otu4oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "class CNN:\n",
        "    def __init__(self, max_neighbours: int = 5, n_jobs: int = -1):\n",
        "        self.max_neighbours = max_neighbours\n",
        "        self.filter = Filter(parameters = {})\n",
        "        self.n_jobs = n_jobs\n",
        "        self.clf = KNeighborsClassifier(n_neighbors = 1, n_jobs = self.n_jobs)\n",
        "\n",
        "    def __call__(self, data: t.Sequence, classes: t.Sequence):\n",
        "        self.isNoise = np.array([False] * len(classes))\n",
        "\n",
        "        firstDifIndx = next(indx for indx, num in enumerate(classes) if num != classes[0])\n",
        "        inStore = [0, firstDifIndx]\n",
        "        grabBag = [indx for indx in range(1, firstDifIndx)]\n",
        "        for indx in range(firstDifIndx + 1, len(classes)):\n",
        "            self.clf.fit(data[inStore], classes[inStore])\n",
        "            pred = self.clf.predict(data[indx].reshape(1, -1))\n",
        "            if pred == classes[indx]:\n",
        "                grabBag.append(indx)\n",
        "            else:\n",
        "                inStore.append(indx)\n",
        "        keepOn = True\n",
        "        while(keepOn):\n",
        "            keepOn = False\n",
        "            for indx in grabBag:\n",
        "                self.clf.fit(data[inStore], classes[inStore])\n",
        "                pred = self.clf.predict(data[indx].reshape(1, -1))\n",
        "                if (pred != classes[indx]):\n",
        "                    inStore.append(indx)\n",
        "                    grabBag.remove(indx)\n",
        "                    keepOn = True\n",
        "        self.filter.rem_indx = grabBag\n",
        "        self.filter.rem_indx.sort()\n",
        "        notNoise = inStore\n",
        "        notNoise.sort()\n",
        "        self.filter.set_cleanData(data[notNoise], classes[notNoise])\n",
        "    print(filter)\n",
        "\n",
        "cnn=CNN(iris.data, iris.target)\n",
        "print(\"clf\", cnn.clf)\n",
        "print(\"filter\", cnn.filter)\n",
        "print(\"max\", cnn.max_neighbours)\n",
        "print(\"n\", cnn.n_jobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crHK5juatLyU",
        "outputId": "4418197f-b873-49f6-cd6b-39c3f6be97e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'filter'>\n",
            "clf KNeighborsClassifier(n_jobs=array([             0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              0,              0,\n",
            "                    0,              0,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    1,              1,              1,              1,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2,              2,              2,\n",
            "                    2,              2, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000, 10000000000000,\n",
            "       10000000000000, 10000000000000, 10000000000000]),\n",
            "                     n_neighbors=1)\n",
            "filter <__main__.Filter object at 0x7f78959f6f40>\n",
            "max [['5.1' '3.5' '1.4' '0.2']\n",
            " ['4.9' '3.0' '1.4' '0.2']\n",
            " ['4.7' '3.2' '1.3' '0.2']\n",
            " ['4.6' '3.1' '1.5' '0.2']\n",
            " ['5.0' '3.6' '1.4' '0.2']\n",
            " ['5.4' '3.9' '1.7' '0.4']\n",
            " ['4.6' '3.4' '1.4' '0.3']\n",
            " ['5.0' '3.4' '1.5' '0.2']\n",
            " ['4.4' '2.9' '1.4' '0.2']\n",
            " ['4.9' '3.1' '1.5' '0.1']\n",
            " ['5.4' '3.7' '1.5' '0.2']\n",
            " ['4.8' '3.4' '1.6' '0.2']\n",
            " ['4.8' '3.0' '1.4' '0.1']\n",
            " ['4.3' '3.0' '1.1' '0.1']\n",
            " ['5.8' '4.0' '1.2' '0.2']\n",
            " ['5.7' '4.4' '1.5' '0.4']\n",
            " ['5.4' '3.9' '1.3' '0.4']\n",
            " ['5.1' '3.5' '1.4' '0.3']\n",
            " ['5.7' '3.8' '1.7' '0.3']\n",
            " ['5.1' '3.8' '1.5' '0.3']\n",
            " ['5.4' '3.4' '1.7' '0.2']\n",
            " ['5.1' '3.7' '1.5' '0.4']\n",
            " ['4.6' '3.6' '1.0' '0.2']\n",
            " ['5.1' '3.3' '1.7' '0.5']\n",
            " ['4.8' '3.4' '1.9' '0.2']\n",
            " ['5.0' '3.0' '1.6' '0.2']\n",
            " ['5.0' '3.4' '1.6' '0.4']\n",
            " ['5.2' '3.5' '1.5' '0.2']\n",
            " ['5.2' '3.4' '1.4' '0.2']\n",
            " ['4.7' '3.2' '1.6' '0.2']\n",
            " ['4.8' '3.1' '1.6' '0.2']\n",
            " ['5.4' '3.4' '1.5' '0.4']\n",
            " ['5.2' '4.1' '1.5' '0.1']\n",
            " ['5.5' '4.2' '1.4' '0.2']\n",
            " ['4.9' '3.1' '1.5' '0.2']\n",
            " ['5.0' '3.2' '1.2' '0.2']\n",
            " ['5.5' '3.5' '1.3' '0.2']\n",
            " ['4.9' '3.6' '1.4' '0.1']\n",
            " ['4.4' '3.0' '1.3' '0.2']\n",
            " ['5.1' '3.4' '1.5' '0.2']\n",
            " ['5.0' '3.5' '1.3' '0.3']\n",
            " ['4.5' '2.3' '1.3' '0.3']\n",
            " ['4.4' '3.2' '1.3' '0.2']\n",
            " ['5.0' '3.5' '1.6' '0.6']\n",
            " ['5.1' '3.8' '1.9' '0.4']\n",
            " ['4.8' '3.0' '1.4' '0.3']\n",
            " ['5.1' '3.8' '1.6' '0.2']\n",
            " ['4.6' '3.2' '1.4' '0.2']\n",
            " ['5.3' '3.7' '1.5' '0.2']\n",
            " ['5.0' '3.3' '1.4' '0.2']\n",
            " ['7.0' '3.2' '4.7' '1.4']\n",
            " ['6.4' '3.2' '4.5' '1.5']\n",
            " ['6.9' '3.1' '4.9' '1.5']\n",
            " ['5.5' '2.3' '4.0' '1.3']\n",
            " ['6.5' '2.8' '4.6' '1.5']\n",
            " ['5.7' '2.8' '4.5' '1.3']\n",
            " ['6.3' '3.3' '4.7' '1.6']\n",
            " ['4.9' '2.4' '3.3' '1.0']\n",
            " ['6.6' '2.9' '4.6' '1.3']\n",
            " ['5.2' '2.7' '3.9' '1.4']\n",
            " ['5.0' '2.0' '3.5' '1.0']\n",
            " ['5.9' '3.0' '4.2' '1.5']\n",
            " ['6.0' '2.2' '4.0' '1.0']\n",
            " ['6.1' '2.9' '4.7' '1.4']\n",
            " ['5.6' '2.9' '3.6' '1.3']\n",
            " ['6.7' '3.1' '4.4' '1.4']\n",
            " ['5.6' '3.0' '4.5' '1.5']\n",
            " ['5.8' '2.7' '4.1' '1.0']\n",
            " ['6.2' '2.2' '4.5' '1.5']\n",
            " ['5.6' '2.5' '3.9' '1.1']\n",
            " ['5.9' '3.2' '4.8' '1.8']\n",
            " ['6.1' '2.8' '4.0' '1.3']\n",
            " ['6.3' '2.5' '4.9' '1.5']\n",
            " ['6.1' '2.8' '4.7' '1.2']\n",
            " ['6.4' '2.9' '4.3' '1.3']\n",
            " ['6.6' '3.0' '4.4' '1.4']\n",
            " ['6.8' '2.8' '4.8' '1.4']\n",
            " ['6.7' '3.0' '5.0' '1.7']\n",
            " ['6.0' '2.9' '4.5' '1.5']\n",
            " ['5.7' '2.6' '3.5' '1.0']\n",
            " ['5.5' '2.4' '3.8' '1.1']\n",
            " ['5.5' '2.4' '3.7' '1.0']\n",
            " ['5.8' '2.7' '3.9' '1.2']\n",
            " ['6.0' '2.7' '5.1' '1.6']\n",
            " ['5.4' '3.0' '4.5' '1.5']\n",
            " ['6.0' '3.4' '4.5' '1.6']\n",
            " ['6.7' '3.1' '4.7' '1.5']\n",
            " ['6.3' '2.3' '4.4' '1.3']\n",
            " ['5.6' '3.0' '4.1' '1.3']\n",
            " ['5.5' '2.5' '4.0' '1.3']\n",
            " ['5.5' '2.6' '4.4' '1.2']\n",
            " ['6.1' '3.0' '4.6' '1.4']\n",
            " ['5.8' '2.6' '4.0' '1.2']\n",
            " ['5.0' '2.3' '3.3' '1.0']\n",
            " ['5.6' '2.7' '4.2' '1.3']\n",
            " ['5.7' '3.0' '4.2' '1.2']\n",
            " ['5.7' '2.9' '4.2' '1.3']\n",
            " ['6.2' '2.9' '4.3' '1.3']\n",
            " ['5.1' '2.5' '3.0' '1.1']\n",
            " ['5.7' '2.8' '4.1' '1.3']\n",
            " ['6.3' '3.3' '6.0' '2.5']\n",
            " ['5.8' '2.7' '5.1' '1.9']\n",
            " ['7.1' '3.0' '5.9' '2.1']\n",
            " ['6.3' '2.9' '5.6' '1.8']\n",
            " ['6.5' '3.0' '5.8' '2.2']\n",
            " ['7.6' '3.0' '6.6' '2.1']\n",
            " ['4.9' '2.5' '4.5' '1.7']\n",
            " ['7.3' '2.9' '6.3' '1.8']\n",
            " ['6.7' '2.5' '5.8' '1.8']\n",
            " ['7.2' '3.6' '6.1' '2.5']\n",
            " ['6.5' '3.2' '5.1' '2.0']\n",
            " ['6.4' '2.7' '5.3' '1.9']\n",
            " ['6.8' '3.0' '5.5' '2.1']\n",
            " ['5.7' '2.5' '5.0' '2.0']\n",
            " ['5.8' '2.8' '5.1' '2.4']\n",
            " ['6.4' '3.2' '5.3' '2.3']\n",
            " ['6.5' '3.0' '5.5' '1.8']\n",
            " ['7.7' '3.8' '6.7' '2.2']\n",
            " ['7.7' '2.6' '6.9' '2.3']\n",
            " ['6.0' '2.2' '5.0' '1.5']\n",
            " ['6.9' '3.2' '5.7' '2.3']\n",
            " ['5.6' '2.8' '4.9' '2.0']\n",
            " ['7.7' '2.8' '6.7' '2.0']\n",
            " ['6.3' '2.7' '4.9' '1.8']\n",
            " ['6.7' '3.3' '5.7' '2.1']\n",
            " ['7.2' '3.2' '6.0' '1.8']\n",
            " ['6.2' '2.8' '4.8' '1.8']\n",
            " ['6.1' '3.0' '4.9' '1.8']\n",
            " ['6.4' '2.8' '5.6' '2.1']\n",
            " ['7.2' '3.0' '5.8' '1.6']\n",
            " ['7.4' '2.8' '6.1' '1.9']\n",
            " ['7.9' '3.8' '6.4' '2.0']\n",
            " ['6.4' '2.8' '5.6' '2.2']\n",
            " ['6.3' '2.8' '5.1' '1.5']\n",
            " ['6.1' '2.6' '5.6' '1.4']\n",
            " ['7.7' '3.0' '6.1' '2.3']\n",
            " ['6.3' '3.4' '5.6' '2.4']\n",
            " ['6.4' '3.1' '5.5' '1.8']\n",
            " ['6.0' '3.0' '4.8' '1.8']\n",
            " ['6.9' '3.1' '5.4' '2.1']\n",
            " ['6.7' '3.1' '5.6' '2.4']\n",
            " ['6.9' '3.1' '5.1' '2.3']\n",
            " ['5.8' '2.7' '5.1' '1.9']\n",
            " ['6.8' '3.2' '5.9' '2.3']\n",
            " ['6.7' '3.3' '5.7' '2.5']\n",
            " ['6.7' '3.0' '5.2' '2.3']\n",
            " ['6.3' '2.5' '5.0' '1.9']\n",
            " ['6.5' '3.0' '5.2' '2.0']\n",
            " ['6.2' '3.4' '5.4' '2.3']\n",
            " ['5.9' '3.0' '5.1' '1.8']\n",
            " ['1000000000' '100000000000' '1000000000' 'blob']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']\n",
            " ['1000000000' '100000000000' '1000000000' '1000000000']]\n",
            "n [             0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              0              0\n",
            "              0              0              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              1              1              1              1\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2              2              2\n",
            "              2              2 10000000000000 10000000000000\n",
            " 10000000000000 10000000000000 10000000000000 10000000000000\n",
            " 10000000000000 10000000000000 10000000000000 10000000000000\n",
            " 10000000000000 10000000000000 10000000000000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame of given iris dataset.\n",
        "import pandas as pd\n",
        "data=pd.DataFrame({\n",
        "    'sepal length':cnn.max_neighbours[:,0],\n",
        "    'sepal width':cnn.max_neighbours[:,1],\n",
        "    'petal length':cnn.max_neighbours[:,2],\n",
        "    'petal width':cnn.max_neighbours[:,3],\n",
        "    'species':cnn.n_jobs\n",
        "})\n",
        "data.head()\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "PMWiUcAFmord",
        "outputId": "b3378b64-f7b1-447f-e291-5e6dccfc2fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-03d10516fa31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating a DataFrame of given iris dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m data=pd.DataFrame({\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'sepal length'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_neighbours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'sepal width'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_neighbours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
        "y=data['species']  # Labels\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
      ],
      "metadata": {
        "id": "3FzipFXfmt1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "gQd53S4NmQjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "species_idx = clf.predict([[3, 5, 4, 2]])[0]\n",
        "iris.target_names[species_idx]\n",
        "\n",
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
        "feature_imp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Creating a bar plot\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "i-4CB3qipJTP",
        "outputId": "86623b06-0f4c-44e5-a3a2-062296d6e317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAEWCAYAAAAJory2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlWUlEQVR4nO3de5xWZb338c9XRAfkpEAJEo6h4gEFhSg8hW539bIyesSsUGPrzm2WbnePttumZh4qdVePaeZGt4/moSy2GsnjgVTwnIJyFNFUUpQ8oCIqqMDv+WNdI4txZta6mZn7Hobv+/WaF+t4Xb91zTC/ua513WspIjAzM7PmbVbrAMzMzDo6J0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRp1gJJCySNbec6QtKOafkySWeUOOctSR9vz7jMbB0nS9tkSbpN0tlNbP+SpL9L2jwido+I6dWKKSKOj4hzShzXIyKeaev6JZ0l6dq2LndDSJoo6b42LK/w2iQtlrQy/THS8DWwlfUulnRwa8qw2nOytE3Z1cCRktRo+1HAdRGxugYxGSBp8xpW/8X0x0jD14s1jKXWbWGJk6Vtym4G+gL7N2yQtDXwBeA3af2DXoGk0ZJmSnpT0kuSfp62j5W0JF9wE+c9KOkNSUslXSJpi6YCknSVpHPT8p8a9XDWSpqY9uWHbq+S9CtJUyWtkPQXSUNyZX5G0iJJyyVdKmmGpH8u00CpnhMkPZXKPkfSEEkPpHb4fcO1NLSDpNMkvZraYEKurN6SfiPpFUl/k3S6pM3SvomS7pf0C0nLgBuAy4Ax6drfSMd9XtJjqe7nJZ2VK78+xfsNSc+lGH6Q9n0OOA04IpU3p8z1N4r9v9P37wVJ50rqkvYNkXSXpGWpzusk9Un7rgEGAw3fy++V+Hk5S9JkSddKehOYWFD/jul7ujzVf0Ml12blOFnaJisiVgK/B47Obf4K8ERENPXL9CLgoojoBQxJ55axBvg3oB8wBvgH4IQS8X3QwwEOB/4O3NnM4V8FfgRsDfwVOA9AUj9gMvAfZH8YLAL2KRl3g88CI4FPAd8DJgFHAh8DhgFfyx27Ldl1bgd8A5gkaWjadzHQG/g48Gmydv+n3LmfBJ4BPprKPx54MLVBn3TM2+m8PsDngW9JGtco3v2AoWTtfKakXSPiNuDHwA2pvOEVtsFVwGpgR2Av4DNAwx8cAn4CDAR2JWuXswAi4ijgOdb1Vi8oWd+XyL5vfYDrCuo/B7iD7Hs/iKydrY05Wdqm7mpgvKS6tH502taU94EdJfWLiLci4qEyFUTErIh4KCJWR8Ri4L/IkkUpknZOMX0lIp5v5rCbIuLhNHR8HTAibT8EWBARN6Z9vyRLupW4ICLejIgFwHzgjoh4JiKWA7eS/fLOOyMi3o2IGcBU4CupF/RV4D8iYkVqh5+RDXk3eDEiLk7ttLKpQCJiekTMi4i1ETEX+C0fbssfRcTK9AfPHKDSxHhzGgV4Q9LNkj5K1o4nR8TbEfEy8It0PUTEXyNiWrrmV4CfNxFTpR6MiJsjYi3Qq6X6yX4utwcGRsSqiGiz+7y2jpOlbdLSL5ZXgXFp6HI0cH0zhx8L7Aw8IekRSV8oU4eknSXdomzS0JtkPZx+Jc/tDfwROL3gl2A+Ab4D9EjLA4EPEmxkb05YbwiwhJdyyyubWO+RW389It7Orf8txdAP6JrW8/u2y60394fAByR9UtLdaSh3OVnvs3FbNtcWZY2LiD7paxxZIuoKLG1IomR/8HwkxfRRSb9Lw6NvAtc2EVOl8m3RYv1kvX0BDyubvX1MK+u2JjhZmmX3J48mG/q7PSJeauqgiHgqIr5G9kvqfGCypK3Ihga7NxyXelH9c6f+GngC2CkN4Z5G9sutRel+3vXA3RExaUMuDFhKNjTXUKby6+1g69QmDQYDL5L9QdLQA8rveyG33vgVSE29Eul6YArwsYjoTXZfs7AtWyivjOeBd4F+uSTaKyJ2T/t/nMreI31/j2wUU+N6i35eGp/TYv0R8feI+GZEDAT+BbhU6X62tR0nS7MsWR4MfJPmh2CRdKSk/mlo7I20eS3wJFCXJp90BU4Htsyd2hN4E3hL0i7At0rGdR6wFfCvFVxLY1OBPSSNUzar8ttk9xXb048kbSFpf7LJUn+IiDVk93jPk9RT0vbAd8l6Yc15CRik9SdD9QRei4hVkkYDX68grpeA+oZJRWVFxFKye4I/k9RL0mZpUk/DUGtP4C1guaTtgFObqDf/mdiin5eK6pd0uKSGP4BeJ0u0ayu5RivmZGmbvHT/7AGyxDSlhUM/ByyQ9BbZZJ+vpntjy8km7FxB1lN6m/WHOk8h+6W+AricbKZnGV8jm1TzutbNiJ1QdFJeRLxKNjnoAmAZsBswk6yn0h7+TvYL+0Wye6fHR8QTad+JZG3zDHAfWS/xyhbKugtYAPxd0qtp2wnA2ZJWAGdSfpIVwB/Sv8skPVrBeZCNPGwBPE52fZOBAWnfj4C9geVkf5zc2OjcnwCnpyHUU0r8vFRa/yeAv6SfyynAv7bHZ3A3dfLLn802HalXtQSYEBF3t3HZY4FrI6I9h3nNasI9S7NOTtJnJfWRtCXr7peWmslrZhknS7PObwzwNNkkmy+SzfZs8qMZZtY0D8OamZkVcM/SzMysgB/Q28n069cv6uvrax2GmdlGZdasWa9GROPPu37AybKTqa+vZ+bMmbUOw8xsoyLpby3t9zCsmZlZASdLMzOzAk6WZmZmBXzP0szMOpX333+fJUuWsGrVqg/tq6urY9CgQXTt2rWiMp0sO5mFS5Yx8tTf1DoMM7OqmnXhune4L1myhJ49e1JfX0/2op1MRLBs2TKWLFnCDjvsUFH5HoY1M7NOZdWqVfTt23e9RAkgib59+zbZ4yziZGlmZp1O40RZtL2Ik6WZmVkBJ0szM7MCTpZmZtbpNPeSkA19eYiTpZmZdSp1dXUsW7bsQ4mxYTZsXV1dxWX6oyNmZtapDBo0iCVLlvDKK698aF/D5ywr5WRpZmadSteuXSv+HGURD8OamZkVcLI0MzMr4GRpZmZWwMnSzMysgJOlmZlZASdLMzOzAk6WZmZmBZwszczMCjhZmpmZFehwyVLSREkDSxx3laTxZbe3QVyn5ZbrJc0ved7Jko4uPrKwnO9IOqa15ZiZWeU6XLIEJgKFybIGTis+ZH2SNgeOAa5vg/qvBE5sg3LMzKxC7ZosUw/sCUnXSVooabKk7mnfSEkzJM2SdLukAalHOAq4TtJsSd0knSnpEUnzJU1SBa+5bqqOtH26pPMlPSzpSUn7p+3dJf1e0uOSbpL0F0mjJP0U6JZiui4V30XS5ZIWSLpDUrcmQjgIeDQiVqfyd5T0Z0lzJD0qaYiksSnGP0p6RtJPJU1Isc2TNAQgIt4BFksavYHfDjMz20DV6FkOBS6NiF2BN4ETJHUFLgbGR8RIsl7TeRExGZgJTIiIERGxErgkIj4REcOAbsAXylTaXB25QzaPiNHAycAP07YTgNcjYjfgDGAkQER8H1iZYpqQjt0J+FVE7A68ARzWRBj7ArNy69elc4YD+wBL0/bhwPHArsBRwM4ptitYvzc5E9i/zPWbmVnbqcZbR56PiPvT8rXAScBtwDBgWuoodmFd4mjsQEnfA7oD2wALgD+VqHdoQR03pn9nAfVpeT/gIoCImC9pbgvlPxsRs5soI28AsBBAUk9gu4i4KZW/Km0HeCQilqb1p4E70vnzgANz5b0M7NK4EknHAccBbNGzbwshm5nZhqhGsmz8WuoABCyIiDEtnSipDrgUGBURz0s6Cyj71s6iOt5N/65hw9rh3dzyGrJeb2MrKRdvvqy1ufW1jWKrS2WuJyImAZMAttp2hw17DbiZmTWrGsOwgyU1JKyvA/cBi4D+DdsldZW0ezpmBdAzLTckmlcl9QAqmeXaUh3NuR/4Sjp+N2CP3L7309BuJRYCOwJExApgiaRxqfwtG+7fVmBnoNQsXDMzazvVSJaLgG9LWghsDfw6It4jS3znS5oDzCa7hwdwFXCZpNlkPazLyRLE7cAjZSstqKM5l5Il2MeBc8mGfJenfZOAubkJPmXcChyQWz8KOCkN7z4AbFtBWZDdA51W4TlmZtZKimi/UTtJ9cAtaXJOhyepC9A1IlalWah/BoamxLuhZd4EfC8inmplbHsB342Io1o6bqttd4hdjvpRa6oyM9vozLqwdR9nlzQrIkY1t78a9yw3Jt2Bu9Nwq4ATWpMok++TTfRpVbIE+pHN0DUzsypr12QZEYvJZqRuFNJ9xWb/stjAMheRDUW3thwPv5qZ1UhHfIKPmZlZh+JkaWZmVsDJ0szMrICTpZmZWQEnSzMzswJOlmZmZgWcLM3MzAo4WZqZmRVwsjQzMyvgZGlmZlbAydLMzKyAk6WZmVkBJ0szM7MCTpZmZmYF/D7LTmbXQX2Z2cqXoJqZ2frcszQzMyvgZGlmZlbAydLMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRpZmZWwI+762TeW7qA587eo9ZhmFkHMPjMebUOodNwz9LMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRpZmZWwMnSzMysgJOlmZlZASdLMzOzAk6WZmZmBZwszczMCjhZmpmZFXCyNDMzK+BkaWZmVsDJ0szMrICTpZmZWYEOnywlTZQ0sMRxV0kavwHlHy/p6Ca210uan5ZHSDokt+8sSaeUKFuS7pLUq9K4mijrz5K2bm05ZmZWuQ6fLIGJQGGy3FARcVlE/KbgsBHAIQXHNOUQYE5EvLkB5zZ2DXBCG5RjZmYVqmqyTL21JyRdJ2mhpMmSuqd9IyXNkDRL0u2SBqSe4ijgOkmzJXWTdKakRyTNlzRJklqo7yOSZqXl4ZJC0uC0/rSk7vleYophjqQ5wLfTti2As4EjUgxHpOJ3kzRd0jOSTmomhAnAH3PxHC1pbqrjmrTtKkm/lvRQKmuspCtT+1yVK2sK8LUKm9zMzNpALXqWQ4FLI2JX4E3gBEldgYuB8RExErgSOC8iJgMzgQkRMSIiVgKXRMQnImIY0A34QnMVRcTLQF0aBt0/lbW/pO2BlyPinUan/F/gxIgYnivjPeBM4IYUww1p1y7AZ4HRwA/TNTS2L9CQrHcHTgcOSuX/a+64rYExwL+RJcVfALsDe0gakeJ4HdhSUt/GlUg6TtJMSTNfe3tNc81hZmYbqBbJ8vmIuD8tXwvsR5ZAhwHTJM0mSyqDmjn/QEl/kTQPOIgsqbTkAbKkdQDw4/Tv/sC9+YMk9QH6RMQ9adM1BeVOjYh3I+JV4GXgo00cs01ErEjLBwF/SMcTEa/ljvtTRAQwD3gpIuZFxFpgAVCfO+5lmhiSjohJETEqIkZts1WXgrDNzKxSm9egzmhiXcCCiBjT0omS6oBLgVER8byks4C6gvruIUuO25MNif57qnNq5aGv593c8hqabsvVkjZLia9MWWsblbu2Ubl1wMpKAzUzs9apRc9ysKSGpPh14D5gEdC/YbukrmnYEmAF0DMtNyTGVyX1AMrMfr0XOBJ4KiWt18gm3tyXPygi3gDekLRf2jQhtzsfQyUWAR9Py3cBhzcMo0rappKC0r3ZbYHFGxCHmZm1Qi2S5SLg25IWkt2r+3W6LzgeOD9NrpkN7JOOvwq4LA3PvgtcDswHbgceKaosIhaT9VwbhlfvA95I9wAb+yfgV6mu/MShu8km9OQn+JQxFRib4lgAnAfMSNf48wrKARgJPBQRqys8z8zMWknZrbIqVSbVA7ekyTmdnqQBwG8i4h/boKyLgCkRcWdLx+25Xbe45V92bG11ZtYJDD5zXq1D2GhImhURo5rbvzF8znKjFRFLgcvb4qEEwPyiRGlmZu2jqhN80pDoJtGrbBARv2+jci5vi3LMzKxypXqWkoZI2jItj5V0UvqohZmZWadXdhj2f4A1knYEJgEfA65vt6jMzMw6kLLJcm2ahfll4OKIOBUY0H5hmZmZdRxlk+X7kr4GfAO4JW1r6vFuZmZmnU7ZZPlPZM8uPS8inpW0A8WPgzMzM+sUSs2GjYjHJf07MDitPwuc356BmZmZdRRlZ8N+keypOrel9RGSprRjXGZmZh1G2WHYs8heRfUGQETMZt0zT83MzDq10hN8ImJ5o21Fb9IwMzPrFMo+wWeBpK8DXSTtBJxE9p5IMzOzTq9sz/JEspcsv0v2MILlwMntFJOZmVmHUtizlNQFmBoRBwI/aP+QzMzMOpbCnmVErAHWSupdhXjMzMw6nLL3LN8C5kmaBrzdsDEiTmqXqMzMzDqQssnyxvRlHdwWA3Zn8Jkzax2GmVmnUvYJPle3dyBmZmYdValkKelZIBpvjwg/mMDMzDq9ssOwo3LLdcDhwDZtH46ZmVnHU+pzlhGxLPf1QkT8H+Dz7RuamZlZx1B2GHbv3OpmZD3Nsr1SMzOzjVrZhPez3PJq4FngK20fjpmZWcdTNlkeGxHP5DekF0CbmZl1emWfDTu55DYzM7NOp8WepaRdyB6g3lvS/8rt6kU2K9bMzKzTKxqGHQp8AegDfDG3fQXwzXaKyczMrENRxIeeNfDhg6QxEfFgFeKxVuoxuEcMP3V4rcPoUO4/8f5ah2BmHZykWRExqrn9ZSf4PCbp22RDsh8Mv0bEMa2Mz8zMrMMrO8HnGmBb4LPADGAQ2VCsmZlZp1c2We4YEWcAb6eHqn8e+GT7hWVmZtZxlE2W76d/35A0DOgNfKR9QjIzM+tYyt6znCRpa+AMYArQAziz3aIyMzPrQMq+z/KKtDgD8Gu5zMxsk1JqGFbSRyX9t6Rb0/puko5t39DMzMw6hrL3LK8CbgcGpvUngZPbIR4zM7MOp2yy7BcRvwfWAkTEamBNu0VlZmbWgZRNlm9L6gsEgKRPAcvbLSozM7MOpOxs2O+SzYIdIul+oD8wvt2iMjMz60CK3joyOCKei4hHJX2a7MHqAhZFxPstnWtmZtZZFA3D3pxbviEiFkTEfCdKMzPblBQlS+WW/flKMzPbJBUly2hm2czMbJNRNMFnuKQ3yXqY3dIyaT0iole7RmdmZtYBtJgsI6JLtQIxMzPrqMp+zrJDkTRW0i1lt7dBfeMk7ZZbny6p2Tdq544b0BbxSOov6bbWlmNmZhtmo0yWNTAO2K3ooCZ8F7i8tZVHxCvAUkn7trYsMzOrXLskS0lbSZoqaY6k+ZKOSNtHSpohaZak2yUNSNunS7pI0ux0/Oi0fbSkByU9JukBSUMrjOFKSQ+n87+Utk+UdKOk2yQ9JemC3DnHSnoynXO5pEsk7QMcClyY4huSDj88HfekpP2bCeMw4LZUdhdJ/5mub66kE9P2xZJ+ksqeKWnv1DZPSzo+V9bNwISy129mZm2n7BN8KvU54MWI+DyApN6SugIXA1+KiFdSAj0POCad0z0iRkg6ALgSGAY8AewfEaslHQz8mCwBlfED4K6IOEZSH+BhSX9O+0YAewHvAoskXUz2rNszgL2BFcBdwJyIeEDSFOCWiJicrgdg84gYLekQ4IfAwfnKJe0AvB4R76ZNxwH1wIh0PdvkDn8uXfsvyB5avy9QB8wHLkvHzATObepCJR2XymeLrbco2TxmZlZWeyXLecDPJJ1PlmTulTSMLAFOS8mmC7A0d85vASLiHkm9UoLrCVwtaSeyj650rSCGzwCHSjolrdcBg9PynRGxHEDS48D2QD9gRkS8lrb/Adi5hfJvTP/OIkuCjQ0AXsmtHwxclh5CT0M9yZT07zygR0SsAFZIeldSn4h4A3iZdW99WU9ETAImAfQY3MMf8TEza2Ptkiwj4klJewOHAOdKuhO4CVgQEWOaO62J9XOAuyPiy5LqgekVhCHgsIhYtN5G6ZNkPcoGa9iwdmgoo7nzV5Il6ErKWtsotrW5sutSmWZmVmXtdc9yIPBORFwLXEg2tLkI6C9pTDqmq6Tdc6c13NfcD1ieen69gRfS/okVhnE7cKJSN1bSXgXHPwJ8WtLWkjZn/eHeFWS93Eo8yfo9zmnAv6SyaTQMW8bOZMOyZmZWZe01G3YPsnuEs8nu550bEe+RvankfElzgNnAPrlzVkl6jOwe3bFp2wXAT9L2Snt/55AN286VtCCtNysiXiC7J/owcD+wmHWvIfsdcGqaKDSk6RI+VN7bwNOSdkybrgCeS/HMAb5e2eVwIDC1wnPMzKwNKKL2t7gkTQdOiYiZNY6jR0S8lXp/NwFXRsRNrSjvy8DIiDi9DWK7h2xy1OstHddjcI8Yfurw1lbXqdx/4v21DsHMOjhJsyKi2c/P+3OW6zsr9YbnA8+y/ltXKpYS7eLWBiWpP/DzokRpZmbto71mw1YkIsbWOgaAiDil+KiKy7yiDcp4hVYmbjMz23DuWZqZmRVwsjQzMyvgZGlmZlbAydLMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRpZmZWwMnSzMysgJOlmZlZASdLMzOzAh3iFV3Wdnb5yC5+2bGZWRtzz9LMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRpZmZWwMnSzMysgJOlmZlZAT/urpNZsWgRMw74dLP7P33PjCpGY2bWObhnaWZmVsDJ0szMrICTpZmZWQEnSzMzswJOlmZmZgWcLM3MzAo4WZqZmRVwsjQzMyvgZGlmZlbAydLMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr4GRpZmZWoNMkS0ljJd2yAecNlDS5mX3TJY1Ky6flttdLml+y/JMlHV1pXE2U8x1Jx7S2HDMzq1ynSZYbKiJejIjxJQ49rfiQ9UnaHDgGuL7iwD7sSuDENijHzMwqVLVkKWkrSVMlzZE0X9IRaftISTMkzZJ0u6QBaft0SRdJmp2OH522j5b0oKTHJD0gaWhBvVMl7ZmWH5N0Zlo+W9I3871ESd0k/U7SQkk3Ad3S9p8C3VIs16Wiu0i6XNICSXdI6tZE9QcBj0bE6lTOjpL+nNrgUUlDUo94hqQ/SnpG0k8lTZD0sKR5koYARMQ7wOKGdjAzs+qpZs/yc8CLETE8IoYBt0nqClwMjI+IkWS9p/Ny53SPiBHACWkfwBPA/hGxF3Am8OOCeu8F9pfUG1gN7Ju27w/c0+jYbwHvRMSuwA+BkQAR8X1gZUSMiIgJ6didgF9FxO7AG8BhTdS9LzArt35dOmc4sA+wNG0fDhwP7AocBewcEaOBK1i/NzkzxW1mZlW0eRXrmgf8TNL5wC0Rca+kYcAwYJokgC6sSyAAvwWIiHsk9ZLUB+gJXC1pJyCArgX13gucBDwLTAX+UVJ3YIeIWCSpPnfsAcAvU51zJc1todxnI2J2Wp4F1DdxzABgIYCknsB2EXFTKn9V2g7wSEQsTetPA3ek8+cBB+bKexnYpXElko4DjgP46JZbthCymZltiKoly4h4UtLewCHAuZLuBG4CFkTEmOZOa2L9HODuiPhySnTTC6p+BBgFPANMA/oB32T9Ht+GeDe3vIY0ZNvISqCuwrLW5tbXsv73qC6VuZ6ImARMAhjas2fjNjMzs1aq5j3LgWRDnNcCFwJ7A4uA/pLGpGO6Sto9d1rDfc39gOURsRzoDbyQ9k8sqjci3gOeBw4HHiTraZ7Ch4dgSdu+nuocBuyZ2/d+GjauxEJgxxTHCmCJpHGp/C1TD7cSOwOlZuGamVnbqeY9yz2AhyXNJrsfeG5KZOOB8yXNAWaT3ctrsErSY8BlwLFp2wXAT9L2sj3je4GXI2JlWh6U/m3s10APSQuBs1m/9zkJmJub4FPGrWRDuw2OAk5Kw7sPANtWUBZk90CnVXiOmZm1kiI65qidpOnAKRExs9axtEaaVfu9iHiqleXsBXw3Io5q6bihPXvGpL32bnb/p++Z0ZowzMw6JUmzImJUc/s3+c9ZVsH3ySb6tFY/4Iw2KMfMzCpUzdmwFYmIsbWOoS1ExCKye7OtLcfDr2ZmNeKepZmZWQEnSzMzswJOlmZmZgWcLM3MzAo4WZqZmRVwsjQzMyvgZGlmZlbAydLMzKyAk6WZmVkBJ0szM7MCTpZmZmYFnCzNzMwKOFmamZkVcLI0MzMr0GFf0WUbpufQoX7Bs5lZG3PP0szMrICTpZmZWQEnSzMzswJOlmZmZgWcLM3MzAooImodg7UhSSuARbWOowPoB7xa6yBqzG2QcTu4DRq01A7bR0T/5k70R0c6n0URMarWQdSapJmbeju4DTJuB7dBg9a0g4dhzczMCjhZmpmZFXCy7Hwm1TqADsLt4DZo4HZwGzTY4HbwBB8zM7MC7lmamZkVcLI0MzMr4GS5kZL0OUmLJP1V0veb2L+lpBvS/r9Iqq9BmO2qRBscIOlRSaslja9FjNVQoh2+K+lxSXMl3Slp+1rE2d5KtMPxkuZJmi3pPkm71SLO9lTUBrnjDpMUkjrlx0lK/CxMlPRK+lmYLemfCwuNCH9tZF9AF+Bp4OPAFsAcYLdGx5wAXJaWvwrcUOu4a9AG9cCewG+A8bWOuYbtcCDQPS1/q7P9LFTQDr1yy4cCt9U67mq3QTquJ3AP8BAwqtZx1+hnYSJwSSXlume5cRoN/DUinomI94DfAV9qdMyXgKvT8mTgHySpijG2t8I2iIjFETEXWFuLAKukTDvcHRHvpNWHgEFVjrEayrTDm7nVrYDONruxzO8FgHOA84FV1Qyuisq2Q0WcLDdO2wHP59aXpG1NHhMRq4HlQN+qRFcdZdpgU1BpOxwL3NquEdVGqXaQ9G1JTwMXACdVKbZqKWwDSXsDH4uIqdUMrMrK/p84LN2amCzpY0WFOlmabSIkHQmMAi6sdSy1EhG/ioghwL8Dp9c6nmqStBnwc+B/1zqWDuBPQH1E7AlMY90oXLOcLDdOLwD5v4QGpW1NHiNpc6A3sKwq0VVHmTbYFJRqB0kHAz8ADo2Id6sUWzVV+vPwO2BcewZUA0Vt0BMYBkyXtBj4FDClE07yKfxZiIhluf8HVwAjiwp1stw4PQLsJGkHSVuQTeCZ0uiYKcA30vJ44K5Id7Y7iTJtsCkobAdJewH/RZYoX65BjNVQph12yq1+HniqivFVQ4ttEBHLI6JfRNRHRD3Z/etDI2JmbcJtN2V+FgbkVg8FFhYV6reObIQiYrWk7wC3k838ujIiFkg6G5gZEVOA/waukfRX4DWyH5hOo0wbSPoEcBOwNfBFST+KiN1rGHabK/mzcCHQA/hDmuP1XEQcWrOg20HJdvhO6mG/D7zOuj8mO4WSbdDplWyHkyQdCqwm+/04sahcP+7OzMysgIdhzczMCjhZmpmZFXCyNDMzK+BkaWZmVsDJ0szMrICTpVkVSVqTe9PB7A15G4ykce31xgxJ9ZLmt0fZLdQ5QtIh1awzV/dmkn4paX56I8kjknaoRSzWsflzlmbVtTIiRrSyjHHALcDjZU+QtHl6RnCHkp4uNYLsMXz/rwYhHAEMBPaMiLWSBgFvt6bAjtrW1jruWZrVmKSRkmZImiXp9oani0j6ZurpzJH0P5K6S9qH7IkjF6ae6RBJ0xseWSapX3qUWcM7+6ZIugu4U9JWkq6U9LCkxyS1+CaGdP7NkqZJWizpO8rejfmYpIckbZOOmy7pohTPfEmj0/Zt0vlz0/F7pu1nSbpG0v3ANcDZwBHp/CMkjZb0YKrnAUlDc/HcKOk2SU9JuiAX6+eUvbt0jqQ707Yy1zsAWBoRawEiYklEvN5CmaWuSVL/9D17JH3tW+nPhXUwtX73mL/8tSl9AWuA2enrJqAr8ADQP+0/guyJIwB9c+edC5yYlq8i935OYDrpvYRAP2BxWp5I9saFbdL6j4Ej03If4Elgq0bx1QPzc+f/leyZov3J3lxzfNr3C+DkXP2Xp+UDcudfDPwwLR8EzE7LZwGzgG65ei7JxdAL2DwtHwz8T+64Z8iec1wH/I3sGaD9yd4ysUM6rpLrHQQsTt+PnwF7pe3NlVn2mq4H9kvLg4GFtf7Z81frvjwMa1Zd6w3DShpG9nDraelRdF2ApWn3MEnnkv2i70H2+K5KTYuI19LyZ4BDJZ2S1utIv8hbOP/uiFgBrJC0nOxtDQDzyF6s3eC3ABFxj6RekvoA+wGHpe13SeorqVc6fkpErGymzt7A1cqe5Rpkf1A0uDMilgNIehzYnuxxhvdExLOprtLXGxFLUs/1oPR1p6TDge7NlFn2mg4GdtO6V8j2ktQjIt5q5pqtg3OyNKstAQsiYkwT+64CxkXEHEkTgbHNlLGadbdU6hrty99/E3BYRCyqIL78G0rW5tbXsv7vj8bPzSx6jmZL9wXPIUvSX1Y2AWp6M/GsoeXfYaWuN7K3T9wK3CrpJbJ7wne0dE4z8te0GfCpiOisL1je5PiepVltLQL6SxoDIKmrpIaHvfcElkrqCkzInbMi7WuwmHWvGBrfQl23AycqdXeUvY2krRyRytwPWJ56f/eS4pY0Fng1It5s4tzG19Obda9Umlii7oeAAxpmsTbcS6XE9UraW9LAtLwZWW/5by2UWfaa7gBOzNUzosR1WAfmZGlWQxHxHlmCO1/SHLJ7Z/uk3WcAfwHuB57InfY74NQ0aWUI8J/AtyQ9RnbPsjnnkA1pzpW0IK23lVWp/suAY9O2s4CRkuYCP6X5t3zcTTZkOVvSEcAFwE9SeYWjXxHxCnAccGNqwxvSrjLX+xHgT8o+LjOXrJd+SQtllr2mk4BRaSLQ48DxRddhHZvfOmJmrSJpOnBKdL73Ipp9wD1LMzOzAu5ZmpmZFXDP0szMrICTpZmZWQEnSzMzswJOlmZmZgWcLM3MzAr8fxWh4TjJEuNKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}